{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be3e773-0363-4906-8d75-dbf84d1483cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import NamedTuple\n",
    "\n",
    "from fractopo import Network\n",
    "from fractopo.general import read_geofile, JOBLIB_CACHE\n",
    "from joblib import Parallel, delayed\n",
    "from fractopo.analysis.length_distributions import determine_fit, calculate_exponent\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188046d9-bc75-498f-96d4-ed9f5f933e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_lengths_1_10 = pd.read_csv(\"../outputs/networks/1_10/trace_lengths.csv\")[\n",
    "    \"lengths\"\n",
    "].values\n",
    "trace_lengths_1_20k = pd.read_csv(\"../outputs/networks/1_20000/trace_lengths.csv\")[\n",
    "    \"lengths\"\n",
    "].values\n",
    "trace_lengths_1_200k = pd.read_csv(\n",
    "    \"../outputs/networks/1_200000_int/trace_lengths.csv\"\n",
    ")[\"lengths\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c7b149-2b86-4348-98bb-3baa5be149d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FitBase(NamedTuple):\n",
    "    xmin: float\n",
    "    data: np.ndarray\n",
    "    alpha: float\n",
    "\n",
    "\n",
    "def determine_censoring_cut_off_fit(censoring_cut_off, lengths):\n",
    "    censor_cut_off_lengths = lengths[lengths < censoring_cut_off]\n",
    "    fit = determine_fit(censor_cut_off_lengths)\n",
    "    return fit.xmin, fit.data, fit.alpha\n",
    "    # fit_base = FitBase(xmin=fit.xmin, data=fit.data, alpha=fit.alpha)\n",
    "    # return fit_base.xmin, fit_\n",
    "\n",
    "\n",
    "@JOBLIB_CACHE.cache\n",
    "def resolve_censoring_fits(lengths: tuple, num: int = 20):\n",
    "    lengths = np.array(lengths)\n",
    "    censoring_cut_offs = np.linspace(\n",
    "        start=lengths.max() + 0.001, stop=lengths.min(), num=num\n",
    "    )\n",
    "    # fits = []\n",
    "\n",
    "    # for censoring_cut_off in censoring_cut_offs:\n",
    "    #     censor_cut_off_lengths = lengths[lengths < censoring_cut_off]\n",
    "    #     fit = determine_fit(censor_cut_off_lengths)\n",
    "    #     fits.append(fit)\n",
    "\n",
    "    fits = Parallel(n_jobs=-1)(\n",
    "        delayed(determine_censoring_cut_off_fit)(\n",
    "            censoring_cut_off=censoring_cut_off,\n",
    "            lengths=lengths,\n",
    "        )\n",
    "        for censoring_cut_off in censoring_cut_offs\n",
    "    )\n",
    "    assert isinstance(fits, list)\n",
    "\n",
    "    return tuple(fits), tuple(censoring_cut_offs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e3009f-763b-4b93-8014-6cde3ed4c7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fits_1_10, censoring_cut_offs_1_10 = resolve_censoring_fits(\n",
    "    tuple(trace_lengths_1_10), num=50\n",
    ")\n",
    "fits_1_20k, censoring_cut_offs_1_20k = resolve_censoring_fits(\n",
    "    tuple(trace_lengths_1_20k), num=50\n",
    ")\n",
    "fits_1_200k, censoring_cut_offs_1_200k = resolve_censoring_fits(\n",
    "    tuple(trace_lengths_1_200k), num=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35eeaa42-a2ef-4b1a-8c60-f83208811c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_effect_of_censoring(censoring_cut_offs, fits, suptitle, lengths):\n",
    "\n",
    "    censoring_cut_offs = np.array(censoring_cut_offs)\n",
    "    fits = [FitBase(xmin=fit[0], data=fit[1], alpha=fit[2]) for fit in fits]\n",
    "\n",
    "    exponents = np.array([calculate_exponent(fit.alpha) for fit in fits])\n",
    "    cut_offs = [fit.xmin for fit in fits]\n",
    "\n",
    "    def _resolve_mask(lengths, censoring_cut_off, cut_off):\n",
    "        lengths_below_censoring = lenghts < censoring_cut_off\n",
    "        lengths_above_cut_off = lengths > cut_off\n",
    "        return lengths_below_censoring & lengths_above_cut_off\n",
    "\n",
    "    cut_off_proportions = np.array(\n",
    "        [1 - (sum(fit.data > fit.xmin) / len(lengths)) for fit in fits]\n",
    "    )\n",
    "\n",
    "    # Plotting\n",
    "    with sns.plotting_context(\"paper\"):\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(8.23, 2.5))\n",
    "\n",
    "        ax_1 = axes[0]\n",
    "        sns.scatterplot(ax=ax_1, x=censoring_cut_offs, y=exponents)\n",
    "        # ax_1.scatter(x=censoring_cut_offs, y=exponents)\n",
    "        ax_1.set_title(\"Censoring cut-off vs.\\npower-law exponent\")\n",
    "        ax_1.set_ylabel(\"Power-law exponent\")\n",
    "        y_max = -1.0\n",
    "        y_min = max([-4.5, exponents[~np.isnan(exponents)].min()]) - 0.5\n",
    "        ax_1.set_ylim(y_min, y_max)\n",
    "        ax_1.vlines(censoring_cut_offs[exponents < y_min], ymin=-5, ymax=-4.9)\n",
    "        ax_1.vlines(censoring_cut_offs[exponents > y_max], ymin=1.1, ymax=0)\n",
    "        # ax_1.yaxis.set_major_locator(ticker.MaxNLocator(integer=False))\n",
    "\n",
    "        ax_2 = axes[1]\n",
    "        sns.scatterplot(ax=ax_2, x=censoring_cut_offs, y=cut_offs)\n",
    "        # ax_2.scatter(x=censoring_cut_offs, y=cut_offs)\n",
    "        ax_2.set_title(\"Censoring cut-off vs.\\ntruncation cut-off\")\n",
    "        ax_2.set_ylabel(\"Truncation cut-off [$m$]\")\n",
    "\n",
    "        ax_3 = axes[2]\n",
    "        sns.scatterplot(ax=ax_3, x=censoring_cut_offs, y=cut_off_proportions)\n",
    "        # ax_3.scatter(x=censoring_cut_offs, y=cut_off_proportions)\n",
    "        ax_3.set_title(\"Censoring cut-off vs.\\ncut-off proportion\")\n",
    "        ax_3.set_ylabel(\"Cut-off proportion\")\n",
    "\n",
    "        for ax in axes:\n",
    "            ax.set_xlabel(\"Censoring cut-off [$m$]\")\n",
    "\n",
    "        fig.subplots_adjust(wspace=0.5)\n",
    "        fig.suptitle(suptitle, x=0.04, y=0.5, rotation=90)\n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f08f71-57e0-4a21-ac99-313ac983294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fits, suptitle, censoring_cut_offs, lengths in zip(\n",
    "    [fits_1_10, fits_1_20k, fits_1_200k],\n",
    "    [\"1:10\", \"1:20k\", \"1:200k\"],\n",
    "    [censoring_cut_offs_1_10, censoring_cut_offs_1_20k, censoring_cut_offs_1_200k],\n",
    "    [trace_lengths_1_10, trace_lengths_1_20k, trace_lengths_1_200k],\n",
    "):\n",
    "    fig, axes = visualize_effect_of_censoring(\n",
    "        fits=fits,\n",
    "        suptitle=suptitle,\n",
    "        censoring_cut_offs=censoring_cut_offs,\n",
    "        lengths=lengths,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b2043e-699b-4b97-8453-f600589fccb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
